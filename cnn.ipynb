{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "from random import shuffle\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DESCR': 'mldata.org dataset: mnist-original',\n 'COL_NAMES': ['label', 'data'],\n 'target': array([0., 0., 0., ..., 9., 9., 9.]),\n 'data': array([[0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        ...,\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0],\n        [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000,), (70000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.target.shape, mnist.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 ** (1/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run /Users/dimatomp/Documents/cnn-mnist/layer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseLayer = InitialLayer((28, 28))\n",
    "conv1 = ConvolutionLayer(baseLayer, (7, 7))\n",
    "conv2 = ConvolutionLayer(baseLayer, (7, 7))\n",
    "conv3 = ConvolutionLayer(baseLayer, (7, 7))\n",
    "conv4 = ConvolutionLayer(baseLayer, (7, 7))\n",
    "sub1 = SubsampleLayer(conv1, (2, 2))\n",
    "sub2 = SubsampleLayer(conv2, (2, 2))\n",
    "sub3 = SubsampleLayer(conv3, (2, 2))\n",
    "sub4 = SubsampleLayer(conv4, (2, 2))\n",
    "comb = CombineLayer(sub1, sub2, sub3, sub4)\n",
    "full1 = FullLayer(comb, (10, 10))\n",
    "result = FullLayer(full1, (1, 10), activation='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r5000 0.4748706772164419 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r10000 0.5331561820441284 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r15000 0.508029485985544 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r20000 0.45772253465530005 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r25000 0.4864931226002865 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r30000 0.42060607659104143 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r35000 0.4817470543688176 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r40000 0.4248827896179317 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r45000 0.39173160092144743 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r50000 0.40354486893605723 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r55000 0.390698589703921 0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35868258460331404"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(zip(mnist.data, mnist.target))\n",
    "shuffle(a)\n",
    "lossFunc = None\n",
    "prevLossFunc = None\n",
    "learnRate = 0.01\n",
    "for i, (data, target) in enumerate(a[:60000]):\n",
    "    if i > 0 and i % 5000 == 0:\n",
    "        print(chr(13) + str(i), lossFunc, learnRate, file=sys.stderr)\n",
    "        #if prevLossFunc is not None and lossFunc > prevLossFunc:\n",
    "        #    learnRate *= 0.5\n",
    "        #prevLossFunc = lossFunc\n",
    "    result.set_input(data.reshape((28, 28)) / 256)\n",
    "    result.forward()\n",
    "    exp = np.exp(result.output)\n",
    "    sumExp = exp.sum()\n",
    "    probs = exp / sumExp\n",
    "    sumExpMinus = sumExp - exp\n",
    "    label = np.where(np.arange(0, 10) == int(target), 1, 0)\n",
    "    sumSecond = (1 - label) / sumExpMinus\n",
    "    sumSecond = sumSecond.sum() - sumSecond\n",
    "    cLoss = 10 * np.log(sumExp) - (label * result.output + (1 - label) * np.log(sumExpMinus)).sum()\n",
    "    lossFunc = cLoss if lossFunc is None else lossFunc * 0.999 + cLoss * 0.001\n",
    "    lossDeriv = 10 * probs - label - exp * sumSecond\n",
    "    result.backward(lossDeriv, learnRate)\n",
    "    \n",
    "# Print the training log loss\n",
    "lossFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35795235755533156, 0.938)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lossFunc = 0\n",
    "nHits = 0\n",
    "for data, target in a[60000:]:\n",
    "    result.set_input(data.reshape((28, 28)) / 256)\n",
    "    result.forward()\n",
    "    if np.argmax(result.output) == int(target):\n",
    "        nHits += 1\n",
    "    exp = np.exp(result.output)\n",
    "    sumExp = exp.sum()\n",
    "    sumExpMinus = sumExp - exp\n",
    "    label = np.where(np.arange(0, 10) == int(target), 1, 0)\n",
    "    lossFunc += 10 * np.log(sumExp) - (label * result.output + (1 - label) * np.log(sumExpMinus)).sum()\n",
    "    \n",
    "# Print the test log loss and accuracy\n",
    "lossFunc / (len(a) - 60000), nHits / (len(a) - 60000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('testmodel.dat', 'wb') as f:\n",
    "    pickle.dump(result, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
